{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "swOU5BJbiltE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e09283-1591-4c04-ef0b-e3468338b00a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hazm in /usr/local/lib/python3.8/dist-packages (0.7.0)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.8/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.10.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install hazm\n",
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://github.com/sobhe/hazm/releases/download/v0.5/resources-0.5.zip\n",
        "# !wget https://github.com/sobhe/hazm/releases/download/v0.5/resources-stanford.zip\n",
        "# !unzip resources-0.5.zip -d resources\n",
        "# !unzip resources-stanford.zip -d resources"
      ],
      "metadata": {
        "id": "XZaoLo2fiu-d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import hazm\n",
        "import string\n",
        "from hazm import *\n",
        "import copy\n",
        "from transformers import pipeline\n"
      ],
      "metadata": {
        "id": "1mTS2EwjixJv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_pSNwmmjdW4",
        "outputId": "e4ded151-8bae-4c3d-aa08-a89477304f37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents_df = pd.read_pickle(\"/content/drive/MyDrive/CNN/documents_embeding_df_full.pkl\")\n",
        "dataset = pd.read_pickle(\"/content/drive/MyDrive/CNN/context_query_question_embeding_df_full.pkl\")"
      ],
      "metadata": {
        "id": "Fo7MgfKDi5NM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop(['search_query_embed'], axis=1)\n",
        "dataset = dataset.drop(['question_embed'], axis=1)\n",
        "dataset = dataset.drop(['context_embed'], axis=1)"
      ],
      "metadata": {
        "id": "MIXhuKH4jD6B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents_df = documents_df.drop(['document_embeds'], axis=1)"
      ],
      "metadata": {
        "id": "TxYMnq2ykVrq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_query_from_question = True\n",
        "number_of_documets_retrival = 1\n",
        "number_of_contexts_retrival = 1"
      ],
      "metadata": {
        "id": "zCpgpxWfkVuP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_search_query(text):\n",
        "    normalizer = Normalizer()\n",
        "    lemmatizer = Lemmatizer()\n",
        "    tagger = POSTagger(model='resources/postagger.model')\n",
        "    chunker = Chunker(model='resources/chunker.model')\n",
        "    # normalize = normalizer.normalize(text)\n",
        "    words = word_tokenize(text)\n",
        "    pos_tags = tagger.tag(words)\n",
        "    tree = chunker.parse(pos_tags)\n",
        "    query_words = []\n",
        "    for subtree in tree.subtrees(filter=lambda t: t.label() == 'NP'):\n",
        "        for word, pos in subtree.leaves():\n",
        "            query_words.append(word)#(lemmatizer.lemmatize(word))\n",
        "    query = ' '.join(query_words)\n",
        "    return query"
      ],
      "metadata": {
        "id": "7H6XG9pKkvXS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_id =121 #19999"
      ],
      "metadata": {
        "id": "IAXKdt3zkxKZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Question = dataset[\"question\"][question_id]\n",
        "Answer = dataset[\"answers\"][question_id]\n",
        "title = dataset[\"title\"][question_id]"
      ],
      "metadata": {
        "id": "br-XsyUikyyU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Question = \" + Question)\n",
        "print(\"title = \"+title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FuonE8-ky2l",
        "outputId": "b6d6c381-311c-431c-f8fc-624f93136315"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question = فوتبال به سبک امروزی در چه سالی آغاز شد؟\n",
            "title = فوتبال\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkGcxEexk2XK",
        "outputId": "cd194f7a-28a4-4a75-ef69-3f10486b9e43"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['اوایل سال ۱۸۰۰ میلادی'], 'answer_start': [199]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Query = create_search_query(Question)"
      ],
      "metadata": {
        "id": "6dm--fyUk4TD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1A5bD7Yfk6Ab",
        "outputId": "8f074fb2-af85-4674-d16d-451c38c670dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'فوتبال سبک امروزی چه سالی'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "======================================================"
      ],
      "metadata": {
        "id": "sKLNMpK-k7j0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TfidfVectorizer object and fit it to the documents\n",
        "vectorizer = TfidfVectorizer(input='content', analyzer='word', norm=None, smooth_idf=True)\n",
        "tfidf_matrix = vectorizer.fit_transform((doc for doc in documents_df['context'].tolist()))\n",
        "\n",
        "# Get the document IDs from the original list of tuples\n",
        "doc_ids = [title for title in documents_df['title'].tolist()]"
      ],
      "metadata": {
        "id": "K77aClYWkVyx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_titles=[]\n",
        "query_vector = vectorizer.transform([Query])\n",
        "# Compute the cosine similarity between the query vector and the document vectors\n",
        "cosine_similarities = np.dot(query_vector, tfidf_matrix.T).toarray()[0]\n",
        "# Sort the documents by their cosine similarity scores\n",
        "sorted_indices = np.argsort(cosine_similarities)[::-1]\n",
        "for j in range(number_of_documets_retrival):\n",
        "  document_index = sorted_indices[j]\n",
        "  document_id = doc_ids[document_index]\n",
        "  output_titles.append(document_id)"
      ],
      "metadata": {
        "id": "m_zzcpnAmQEt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_titles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14_3aOBPmf_I",
        "outputId": "78914f63-d878-4e21-ba25-8a6a824eabc1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['فوتبال']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_contexts_of_titles(titles,dataset):\n",
        "  paragraphs =pd.DataFrame()\n",
        "  for title in titles:\n",
        "    df = dataset[dataset[\"title\"] == title]\n",
        "    if paragraphs.empty:\n",
        "      paragraphs = copy.deepcopy(df)\n",
        "    else:\n",
        "      paragraphs = paragraphs.append(df)\n",
        "  paragraphs = paragraphs.reset_index(drop=True)\n",
        "  return paragraphs"
      ],
      "metadata": {
        "id": "TBNKkeGNmoE5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_paragraphs = get_contexts_of_titles(output_titles,dataset)"
      ],
      "metadata": {
        "id": "2GkKrZi-oJol"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unique(list1):\n",
        "    unique_list = []\n",
        "    for x in list1:\n",
        "        if x not in unique_list:\n",
        "            unique_list.append(x)\n",
        "    return unique_list"
      ],
      "metadata": {
        "id": "-zdnub3MoVfN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_paraghraphs = unique(selected_paragraphs['context'].tolist())"
      ],
      "metadata": {
        "id": "9FY-Py8to_6s"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TfidfVectorizer object and fit it to the documents\n",
        "vectorizer = TfidfVectorizer(input='content', analyzer='word', norm=None, smooth_idf=True)\n",
        "tfidf_matrix = vectorizer.fit_transform((doc for doc in unique_paraghraphs))\n",
        "\n",
        "# Get the document IDs from the original list of tuples\n",
        "doc_ids = [title for title in unique_paraghraphs]"
      ],
      "metadata": {
        "id": "wHwkR9YFpIIr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_paragraphs=[]\n",
        "Question_vector = vectorizer.transform([Question])\n",
        "# Compute the cosine similarity between the query vector and the document vectors\n",
        "cosine_similarities = np.dot(Question_vector, tfidf_matrix.T).toarray()[0]\n",
        "# Sort the documents by their cosine similarity scores\n",
        "sorted_indices = np.argsort(cosine_similarities)[::-1]\n",
        "for j in range(number_of_contexts_retrival):\n",
        "  document_index = sorted_indices[j]\n",
        "  document_id = doc_ids[document_index]\n",
        "  output_paragraphs.append(document_id)"
      ],
      "metadata": {
        "id": "7OEJCezhpWIL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_paragraphs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfiOnF2Rps_m",
        "outputId": "f7c0045e-4792-49b6-d359-29e6f07bd8f9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['پیشینهٔ معاصر این بازی جهانی به بیش از ۱۰۰ سال پیش بازمی\\u200cگردد؛ زمانی که این ورزش در انگلستان شکل\\u200cگرفت و اتحادیه فوتبال انگلستان به وجود آمد و فوتبال به ورزشی رسمی تبدیل\\u200cشد. فوتبال به سبک امروزی، در اوایل سال ۱۸۰۰ میلادی در هفت مدرسهٔ عمومی انگلستان آغاز گردید. شش مدرسه تقریباً همان فوتبال به سبک قدیمی را اجرا می\\u200cکردند؛ اما مدرسهٔ راگبی انگلستان که در سال ۱۵۶۷ تأسیس\\u200cشده بود، نسخه\\u200cای متفاوت از فوتبال را ارائه\\u200cداد. مدارس دیگر نیز قوانینی را ساخته و در پایان، بازی فوتبال مدرن را بنیان\\u200cگذاری کردند. در این سال اندازه و وزن توپ\\u200cها نیز استاندارد شد. در نخستین بازی ۹۰ دقیقه\\u200cای فوتبال، دو تیم لندن و شفیلد در سال ۱۸۶۶ به رقابت با یک\\u200cدیگر پرداختند.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mrr_model = pipeline(task = \"question-answering\" ,model=\"/content/drive/MyDrive/CN/distilbert-fa-zwnj-base-on-pquad-dataset\")\n",
        "# mrr_model = pipeline(task = \"question-answering\" ,model=\"/content/drive/MyDrive/CN/xlm-roberta-base-on-pquad-dataset\")"
      ],
      "metadata": {
        "id": "aJaGlJc9p1DL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = []\n",
        "for paragraph in output_paragraphs:\n",
        "  outputs.append(mrr_model(question=Question, context=paragraph))"
      ],
      "metadata": {
        "id": "hEW-PdKmqGHB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_nvjjMDqLzh",
        "outputId": "026c2e77-a1cd-4496-cffc-e2d5b80a8285"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.5924777984619141,\n",
              "  'start': 199,\n",
              "  'end': 220,\n",
              "  'answer': 'اوایل سال ۱۸۰۰ میلادی'}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}